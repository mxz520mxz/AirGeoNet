{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sunxin/project/AirGeoNet')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from maploc.osm.viz import GeoPlotter\n",
    "from maploc.utils.geo import BoundaryBox, Projection\n",
    "from maploc.osm.tiling import TileManager\n",
    "\n",
    "from pyproj import Proj, transform\n",
    "import csv\n",
    "\n",
    "import cv2 as cv\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms as tvf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from typing import Literal\n",
    "import glob\n",
    "\n",
    "\n",
    "import natsort\n",
    "import einops as ein\n",
    "import pickle\n",
    "from DINOV2.utilities import VLAD,DinoV2ExtractFeatures\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "class LocalArgs:\n",
    "    \n",
    "    # Input directory containing images\n",
    "    in_dir: str = \"/home/sunxin/project/AirGeoNet/datasets/VPAir/VPAir/queries\"\n",
    "    # Image file extension\n",
    "    imgs_ext: str = \"png\"\n",
    "    # Output directory where global descriptors will be stored\n",
    "    out_dir: str = \"/home/sunxin/project/AirGeoNet/datasets/VPAir/VPAir/VLAD_DataBase\"\n",
    "    # gps information \n",
    "    gps_path = '/home/sunxin/project/AirGeoNet/datasets/VPAir/VPAir/poses.csv'\n",
    "    # c_center save path\n",
    "    VLAD_path = '/home/sunxin/project/AirGeoNet/datasets/VPAir/VPAir'\n",
    "    # Maximum edge length (expected) across all images\n",
    "    max_img_size: int = 1024\n",
    " \n",
    "    # Number of clusters (cluster centers for VLAD) - read from cache\n",
    "    num_c: int = 64\n",
    "\n",
    "    desc_layer: int = 31\n",
    "    desc_facet: Literal[\"query\", \"key\", \"value\", \"token\"] = \"value\"\n",
    "\n",
    "    # Domain for use case (deployment environment)\n",
    "    domain = \"vpair\"\n",
    "    # Maximum image dimension\n",
    "    max_img_size: int = 1024\n",
    "\n",
    "    device = 'cuda'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gps_file(path, projection: Projection = None):\n",
    "    all_latlon = []\n",
    "\n",
    "    with open(path, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            all_latlon.append([float(row['lat']),float(row['lon'])])\n",
    "    \n",
    "    return np.array(all_latlon)\n",
    "\n",
    "\n",
    "\n",
    "def prepare_VLAD(\n",
    "    largs\n",
    "):\n",
    "    # Realpath expansion\n",
    "    _ex = lambda x: os.path.realpath(os.path.expanduser(x))\n",
    "    # Dino_v2 properties (parameters)\n",
    "\n",
    "    save_dir = _ex(largs.out_dir)\n",
    "    device = torch.device(largs.device)\n",
    "    \n",
    "    desc_layer: int = largs.desc_layer\n",
    "    desc_facet: Literal[\"query\", \"key\", \"value\", \"token\"] = largs.desc_facet\n",
    "    num_c: int = largs.num_c\n",
    "    domain:str =largs.domain\n",
    "    max_img_size: int = largs.max_img_size\n",
    "      \n",
    "    # Ensure inputs are fine\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        print(f\"Creating directory: {save_dir}\")\n",
    "    else:\n",
    "        print(\"Save directory already exists, overwriting possible!\")\n",
    "\n",
    "    # Load the DINO extractor model\n",
    "    extractor = DinoV2ExtractFeatures(\"dinov2_vitg14\", desc_layer,\n",
    "        desc_facet, device=device)\n",
    "    base_tf = tvf.Compose([ # Base image transformations\n",
    "        tvf.ToTensor(),\n",
    "        tvf.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    imgs_dir = _ex(largs.in_dir)\n",
    "    assert os.path.isdir(imgs_dir), \"Input directory doesn't exist!\"\n",
    "    img_fnames = glob.glob(f\"{imgs_dir}/*.{largs.imgs_ext}\")\n",
    "    img_fnames = natsort.natsorted(img_fnames)\n",
    "\n",
    "    imgs_dir = _ex(largs.in_dir)\n",
    "    assert os.path.isdir(imgs_dir), \"Input directory doesn't exist!\"\n",
    "    img_fnames = glob.glob(f\"{imgs_dir}/*.{largs.imgs_ext}\")\n",
    "    img_fnames = natsort.natsorted(img_fnames)\n",
    "    \n",
    "    img_patch_descs = []\n",
    "    \n",
    "    for img_fname in tqdm(img_fnames):\n",
    "        with torch.no_grad():\n",
    "            pil_img = Image.open(img_fname).convert('RGB')\n",
    "            img_pt = base_tf(pil_img).to(device)\n",
    "            if max(img_pt.shape[-2:]) > max_img_size:\n",
    "                pass\n",
    "            c,h,w = img_pt.shape\n",
    "            h_new, w_new = (h // 14) * 14, (w // 14) * 14\n",
    "            img_pt = tvf.CenterCrop((h_new,w_new))(img_pt)[None,...]\n",
    "            ret = extractor(img_pt)\n",
    "            img_patch_descs.append(ret.to('cpu'))\n",
    "            \n",
    "\n",
    "    result_tensor = torch.cat(img_patch_descs, dim=0)\n",
    "    \n",
    "    vlad = VLAD(num_c, desc_dim=result_tensor[0].shape[1], cache_dir= _ex(largs.VLAD_path))\n",
    "    vlad.fit(ein.rearrange(result_tensor, \"n k d -> (n k) d\"))\n",
    "    \n",
    "    all_latlon = parse_gps_file(largs.gps_path)\n",
    "    vlad_data = []\n",
    "    for img_fname, ret, latlon in tqdm(zip(img_fnames, img_patch_descs, all_latlon), total=len(img_fnames)):\n",
    "\n",
    "        # VLAD global descriptor\n",
    "        gd = vlad.generate(ret.squeeze()) # VLAD:  [agg_dim]\n",
    "        gd_np = gd.numpy()[np.newaxis, ...] # shape: [1, agg_dim]\n",
    "        vlad_data.append({'gd_np':gd_np,'latlon':latlon})\n",
    "\n",
    "    with open(f\"{save_dir}/vlad_descriptors_64.pkl\", 'wb') as file:\n",
    "        pickle.dump(vlad_data, file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save directory already exists, overwriting possible!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/sunxin/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fecfffc2684fe1b9cc67e622bc6f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cache directory already exists: /home/sunxin/project/AirGeoNet/datasets/VPAir/VPAir\n",
      "Caching cluster centers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebb9485c78b4513a597554aa6ee52d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepare_VLAD(LocalArgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AirGeoNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
